{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow Implementation and Metrics Tracking\n",
    "\n",
    "This notebook showcases the implementation of MLFlow into the machine learning platform at ClassPass as a part of my internship and demonstrates how it is used to track metrics and other important aspects of the model development process.The notebook covers the setup process for MLFlow, recording and logging metrics, and visualizing the results. \n",
    "\n",
    "### Table of Contents\n",
    "[Setup](#setup)\n",
    "\n",
    "[Recording Metrics](#recording-metrics)\n",
    "\n",
    "[Logging Artifacts](#logging-artifacts)\n",
    "\n",
    "[Model Evaluation](#model-evaluation)\n",
    "\n",
    "[Conclusion](#conclusion)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/19 14:04:23 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2023/06/19 14:04:23 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '90369ff3c67b4018be5b8aaaafe31c66', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "mlflow.autolog()\n",
    "\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# Create and train models.\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the test dataset.\n",
    "predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from random import random, randint\n",
    "from mlflow import log_metric, log_param, log_params, log_artifacts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Log a parameter (key-value pair)\n",
    "    log_param(\"config_value\", randint(0, 100))\n",
    "\n",
    "    # Log a dictionary of parameters\n",
    "    params = {\"param1\": randint(0, 100), \"param2\": randint(0, 100)}\n",
    "    log_params(params)\n",
    "\n",
    "    # Log a metric; metrics can be updated throughout the run\n",
    "    log_metric(\"accuracy\", random() / 2.0)\n",
    "    log_metric(\"accuracy\", random() + 0.1)\n",
    "    log_metric(\"accuracy\", random() + 0.2)\n",
    "\n",
    "    # Log an artifact (output file)\n",
    "    if not os.path.exists(\"outputs\"):\n",
    "        os.makedirs(\"outputs\")\n",
    "    with open(\"outputs/test.txt\", \"w\") as f:\n",
    "        f.write(\"hello world!\")\n",
    "    log_artifacts(\"outputs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
